{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/WTRcyjmzsfsMfEgd4lpx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 埋め込み表現"],"metadata":{"id":"3BSRyHbiZOgM"}},{"cell_type":"markdown","source":["## セットアップ"],"metadata":{"id":"OgxFyOTEZW8M"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pDE3RYX6ZL_l"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"Gq4tvXrqZeSo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/研究'"],"metadata":{"id":"IsJd2ei5ZnVD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ライブラリのインポート\n","import os\n","import glob\n","import numpy as np\n","import pandas as pd\n","import torch\n","\n","!pip install torch transformers\n","from transformers import AutoTokenizer, AutoModel"],"metadata":{"id":"SdI6w3JYZo9B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## モデル"],"metadata":{"id":"aPNx6rwnpEvr"}},{"cell_type":"code","source":["# ModernBERT\n","model_name = \"answerdotai/ModernBERT-base\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model     = AutoModel.from_pretrained(model_name)\n","device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"9hlCfCnsl4Q3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# カテゴリファイル\n","cat_df = pd.read_csv(\"category.csv\", dtype={\"TransissonId\": str})\n","cond = ''"],"metadata":{"id":"KRpn1tdQlpB7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.to(device)\n","model.eval()\n","\n","# 各ファイルごとに処理\n","results = {}  # 日付 → 平均ベクトル\n","\n","for fp in glob.glob(os.path.join(\"kyodo\", \"*.csv\")):\n","    # ファイル名から日付を取得（例: \"2023-12-24.csv\" → \"2023-12-24\"）\n","    date_str = os.path.splitext(os.path.basename(fp))[0]\n","\n","    # 元データ読み込み\n","    df = pd.read_csv(fp, dtype={\"TransissonId\": str})\n","\n","    # カテゴリマスタとマージ＆フィルタ\n","    merged = df.merge(cat_df, on=\"TransissonId\", how=\"inner\")\n","    filtered = merged[merged[\"category\"] == cond]\n","\n","    # テキスト結合＆埋め込み取得\n","    embeddings = []\n","    for _, row in filtered.iterrows():\n","        text = \" \".join([\n","            row.get(\"Headline\", \"\") or \"\",\n","            row.get(\"SubHeadline\", \"\") or \"\",\n","            row.get(\"NewsContent\", \"\") or \"\"\n","        ])\n","        inputs = tokenizer(\n","            text,\n","            return_tensors=\"pt\",\n","            truncation=True,\n","            max_length=8192\n","        ).to(device)\n","        with torch.no_grad():\n","            out = model(**inputs)\n","        # CLSトークンの埋め込みを numpy ベクトルに\n","        vec = out.last_hidden_state[:,0,:].squeeze().cpu().numpy()\n","        embeddings.append(vec)\n","\n","    # embedding の平均を計算（記事がない日はゼロベクトル）\n","    if embeddings:\n","        embedding = np.stack(embeddings, axis=0).mean(axis=0)\n","    else:\n","        embedding = np.zeros(model.config.hidden_size, dtype=float)\n","\n","    results[date_str] = embedding\n","\n","# 日付インデックスのdataframeにまとめる\n","emb_df = pd.DataFrame.from_dict(results, orient=\"index\")\n","emb_df.index = pd.to_datetime(emb_df.index)\n","emb_df.sort_index(inplace=True)\n","emb_df.columns = [f\"dim_{i}\" for i in range(emb_df.shape[1])]\n","\n","# 結果表示\n","print(emb_df)"],"metadata":{"id":"e2AhX4p3kTyQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 必要に応じて CSV 出力なども可能\n","# emb_df.to_csv(\"daily_average_embeddings.csv\")"],"metadata":{"id":"dr3g3jCOe061"},"execution_count":null,"outputs":[]}]}